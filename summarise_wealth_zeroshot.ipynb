{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Zeroshot Prompting for Summary Generation  \n",
    "\n",
    "\n",
    "By providing a single zeroshot prompt, use llama3 or OpenAI LLMs to summarise a collection of articles on wealth management news and advice.\n",
    "\n",
    "Inputs:\n",
    "- Articles in .txt format in the relative folder destination `./insight_docs`\n",
    "- Choice of LLM `params['model']`\n",
    "- Hyperparameters in the variables `params['model']` and `params['temperature']`\n",
    "- OpenAI API key set as the variable `os.environ['OPENAI_API_KEY']`\n",
    "\n",
    "Outputs:\n",
    "- Log file saved in the home directory as `./zeroshot_summarise_ubs_week_log.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.llms import Ollama\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain.chains.llm import LLMChain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.documents import Document\n",
    "\n",
    "import os\n",
    "os.environ['OPENAI_API_KEY'] = \"[key]\"\n",
    "\n",
    "from datetime import datetime\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarisation Hyperparameters  \n",
    "Adjust the following variables to match your preferences:\n",
    "- Articles in .txt format in the relative folder destination `./insight_docs`\n",
    "- Choice of LLM `params['model']`\n",
    "- Hyperparameters in the variables `params['model']` and `params['temperature']`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file = \"./zeroshot_summarise_ubs_week_log.csv\"\n",
    "params = {}\n",
    "\n",
    "doc_folder = 'insight_docs'\n",
    "params['doc_names'] = [os.path.join(doc_folder,f) for f in os.listdir(doc_folder) if os.path.isfile(os.path.join(doc_folder,f))]\n",
    "params['doc_names'].sort()\n",
    "params['latest_article_date'] = params['doc_names'][-1][:10]\n",
    "\n",
    "# Latest models available as of 25 June 2024\n",
    "#params['model'] = \"llama2:70b\"\n",
    "#params['model'] = \"llama3\"\n",
    "params['model'] = \"gpt-3.5-turbo-0125\"\n",
    "params['model'] = \"gpt-4-turbo-2024-04-09\"\n",
    "\n",
    "params['temperature'] = 0\n",
    "\n",
    "if 'llama3' in params['model']:\n",
    "    llm = Ollama(model=params['model'], num_ctx = 4096,num_predict=-1, num_gpu=1, temperature=params['temperature'],\n",
    "                    stop=[\"<|start_header_id|>\", \"<|end_header_id|>\", \"<|eot_id|>\", \"<|reserved_special_token\"])\n",
    "elif 'llama2' in params['model']:\n",
    "    llm = Ollama(model=params['model'], num_ctx = 4096, num_predict=-1, num_gpu=1, temperature=params['temperature'])   # ,num_ctx=2048\n",
    "else:\n",
    "    llm = ChatOpenAI(temperature=0, model_name=params['model'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prompts  \n",
    "Setup your prompt templates:\n",
    "- System prompt\n",
    "- Summarisation template to summarise all information into an appropriate output format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System Prompt\n",
    "params['system'] = \"You are an experienced investment analyst who writes for the Chief Investment Office at a wealth management firm.\"\n",
    "\n",
    "# User Prompt\n",
    "params['summarise_template'] = '''There is a set of seven articles in quotation marks below. Take these articles and distill them into multiple bite-sized paragraphs. Each paragraph must be structured as shown below. \n",
    "Summary: [summary of key news]\n",
    "Actionable Insights: [point form]\n",
    "\"\"\"{docs}\"\"\"   \n",
    "'''\n",
    "summarise_prompt = ChatPromptTemplate.from_messages([(\"system\", params['system']),(\"user\", params['summarise_template'])])\n",
    "summarise_chain = LLMChain(llm=llm, prompt=summarise_prompt)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = [f[11:-4] for f in os.listdir(doc_folder) if os.path.isfile(os.path.join(doc_folder,f))]\n",
    "\n",
    "docs = []\n",
    "# Load docs\n",
    "for f in params['doc_names']:\n",
    "    loader = TextLoader(f,encoding='UTF-8')\n",
    "    docs.append(loader.load()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine all articles into a single string `all_docs`.  \n",
    "Each article summary is pre-fixed by the article title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_docs = ''\n",
    "\n",
    "for i in range(len(docs)):\n",
    "    all_docs = all_docs+ \"Article \"+str(i+1)+\": \"+titles[i] + \"\\n\" + docs[i].page_content + \"\\n\\n\"\n",
    "\n",
    "print(all_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "params['summary'] = summarise_chain.invoke(all_docs)['text']\n",
    "end = time.time()\n",
    "\n",
    "params['duration'] = end - start\n",
    "print(params['summary'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write Log File  \n",
    "Write all input hyperparameters and LLM outputs into a log file saved in the home directory as `./zeroshot_summarise_ubs_week_log.csv`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datetime object containing current date and time\n",
    "now = datetime.now()\n",
    "params['experiment_date'] = now.strftime(\"%Y-%m-%d\")\n",
    "params['experiment_time'] = now.strftime(\"%H:%M:%S\")\n",
    "try:  \n",
    "    all_params_df = pd.read_csv(log_file)\n",
    "except:\n",
    "    all_params_df = pd.DataFrame()\n",
    "\n",
    "params_df = pd.DataFrame([params])\n",
    "all_params_df = pd.concat([all_params_df,params_df])\n",
    "\n",
    "all_params_df.to_csv(log_file, index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GenAI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
